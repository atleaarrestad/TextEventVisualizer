@page "/articlecollector"
@using Data;
@using Models;
@using Services;
@inject IArticleService ArticleService;
@inject IJsonService JsonService;

<div class="wrapper">
    <div class="container-row">
        <div class="container scraped">
            <span class="count">@unScrapedArticlesCount</span>
            <span class="label">Skeleton articles added from dataset</span>
            <button @onclick="OnParseJsonClickHandler" class="scraper-button" style="margin-right: 8px">Start Add articles from JSON</button>
        </div>

        <div class="container unscraped">

            <span class="count">@unScrapedArticlesCountFiltered</span>
            <span class="label">Articles waiting for content to be gathered</span>

            <div class="container-column">
                <select id="categoryDropdown" name="categoryDropdown" @bind="selectedCategory">
                    @foreach (var category in categories)
                    {
                        <option value="@category">@category</option>
                    }
                </select>
                <div class="container-row">
                    <label for="fromDate">From:</label>
                    <input type="date" id="fromDate" name="fromDate" @bind="fromDate">

                    <label for="toDate">To:</label>
                    <input type="date" id="toDate" name="toDate" @bind="toDate">
                </div>
            </div>




            <div class="container-row">
                <button @onclick="OnScrapeClickHandler" class="scraper-button" style="margin-right: 8px">Start gathering process</button>
            </div>
        </div>

        <div class="container scraped">
            <span class="count">@scrapedArticlesCount</span>
            <span class="label">Articles with content gathered from the web</span>
            <span class="label">Ready for further processing by NLP</span>
        </div>

    </div>

    <div class="container logs">
        <div class="log-header">
            <div class="log-title">Webscraper logs</div>
            <div class="spinner-container">
                @if (isScraperRunning)
                {
                    <div class="spinner"></div>
                }
            </div>
        </div>
        <div class="log-entries">
            @foreach (var log in logs)
            {
                <div class="log-entry">@log</div>
            }
        </div>
    </div>
</div>


@code{
    private List<Article> articles = new();
    private int scrapedArticlesCount = 0;
    private int unScrapedArticlesCount = 0;
    private int unScrapedArticlesCountFiltered = 0;
    private List<string> categories = new();
    private List<string> logs = new();
    private bool isScraperRunning;
    private string _selectedCategory = string.Empty;
    private DateTime? _fromDate;
    private DateTime? _toDate;

    private string selectedCategory
    {
        get => _selectedCategory;
        set
        {
            if (_selectedCategory != value)
            {
                _selectedCategory = value;
                UpdateUnscrapedFilteredCount();
            }
        }
    }

    private DateTime? fromDate
    {
        get => _fromDate;
        set
        {
            if (_fromDate != value)
            {
                _fromDate = value;
                UpdateUnscrapedFilteredCount();
            }
        }
    }

    private DateTime? toDate
    {
        get => _toDate;
        set
        {
            if (_toDate != value)
            {
                _toDate = value;
                UpdateUnscrapedFilteredCount();
            }
        }
    }

    protected async override void OnInitialized()
    {
        scrapedArticlesCount = await ArticleService.GetArticlesCountAsync(scraped: true);
        unScrapedArticlesCount = await ArticleService.GetArticlesCountAsync(scraped: false);
        categories = await ArticleService.GetUniqueCategories();
        this._fromDate = DateTime.Now.AddYears(-15);
        this._toDate = DateTime.Now;
        if (this.categories.Any())
            this.selectedCategory = this.categories[0];
    }

    public async void OnScrapeClickHandler()
    {
        isScraperRunning = true;
        var unscrapedArticles = await ArticleService.GetArticlesAsync(
                scraped: false,
                category: this.selectedCategory,
                from: this.fromDate.Value,
                to: this.toDate.Value);

        foreach (var article in unscrapedArticles)
        {
            await Task.Delay(4000);
            AddLog(4000);

            var result = await WebScraper.Scrape(article.WebUrl);
            if (result.Length > 0)
            {
                article.Content = result;
                article.HasBeenScraped = true;
                await ArticleService.UpdateArticleAsync(article);

                articles.Add(article);
                scrapedArticlesCount += 1;
            }

            unScrapedArticlesCount -= 1;
            unScrapedArticlesCountFiltered -= 1;
            AddLog(article);
        }
        isScraperRunning = false;
        StateHasChanged();
    }
    private async void UpdateUnscrapedFilteredCount()
    {
        Console.WriteLine($"Category: {selectedCategory}, From: {fromDate}, To: {toDate}");
        if (this.fromDate.HasValue && this.toDate.HasValue && !string.IsNullOrWhiteSpace(this.selectedCategory))
            this.unScrapedArticlesCountFiltered = await ArticleService.GetArticlesCountAsync(
                scraped: false,
                category: this.selectedCategory,
                from: this.fromDate.Value,
                to: this.toDate.Value);

    }

    public async void OnParseJsonClickHandler()
    {
        await JsonService.ExtractArticlesFromJsonFile();
    }

    private void AddLog(Article article){
        var logInfo = article.Content.Length > 0
            ? $"Successfully scraped {article.Content.Length} characters - updated database"
            : "Failure, content is empty";

        var log = $"{DateTime.Now.ToString("G")} - {logInfo}";
        this.logs.Insert(0, log);
        StateHasChanged();
    }

    private void AddLog(int delayInMilliseconds)
    {
        var log = $"{DateTime.Now.ToString("G")} - finished waiting {delayInMilliseconds/1000} seconds to reduce load on external website";
        this.logs.Insert(0, log);
        while (this.logs.Count > 250)
        {
            this.logs.RemoveAt(this.logs.Count - 1);
        }
        StateHasChanged();
    }
}
