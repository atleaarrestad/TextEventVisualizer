@page "/articlecollector"
@using Data;
@using Models;
@using Services;

@inject IArticleService ArticleService;
@inject IJsonService JsonService;

<div class="wrapper">
    <div class="container-row">
        <div class="container scraped">
            <span class="count">@unScrapedArticlesCount</span>
            <span class="label">Skeleton articles added from dataset</span>
            <button @onclick="OnParseJsonClickHandler" class="scraper-button @((isJsonExtractorRunning || isJsonAlreadyParsed) ? "disabled" : "")" disabled="@(isJsonAlreadyParsed || isJsonExtractorRunning)" style="margin-right: 8px">Start Add articles from JSON</button>
        </div>

        <div class="container unscraped">

            <span class="count">@unScrapedArticlesCountFiltered</span>
            <span class="label">Articles waiting for content to be gathered</span>

            <div class="container-column">
                <select id="categoryDropdown" name="categoryDropdown" @bind="selectedCategory">
                    @foreach (var category in categories)
                    {
                        <option value="@category">@category</option>
                    }
                </select>
                <div class="container-row">
                    <label for="fromDate">From:</label>
                    <input type="date" id="fromDate" name="fromDate" @bind="fromDate">

                    <label for="toDate">To:</label>
                    <input type="date" id="toDate" name="toDate" @bind="toDate">
                </div>
            </div>

            <div class="container-row">
                <button @onclick="OnScrapeClickHandler" class="scraper-button" style="margin-right: 8px">@(isScraperRunning ? "Stop gathering process" : "Start gathering process")</button>
            </div>
        </div>

        <div class="container scraped">
            <span class="count">@scrapedArticlesCount</span>
            <span class="label">Articles with content gathered from the web</span>
            <span class="label">Ready for further processing by NLP</span>
        </div>

    </div>

    <div class="container logs">
        <div class="log-header">
            <div class="log-title">Webscraper logs</div>
            <div class="spinner-container">
                @if (isScraperRunning || isJsonExtractorRunning)
                {
                    <div class="spinner"></div>
                }
            </div>
        </div>
        <div class="log-entries">
            @foreach (var log in logs)
            {
                <div class="log-entry">@log</div>
            }
        </div>
    </div>
</div>


@code{
    private List<Article> articles = new();
    private int scrapedArticlesCount = 0;
    private int unScrapedArticlesCount = 0;
    private int unScrapedArticlesCountFiltered = 0;
    private List<string> categories = new();
    private List<string> logs = new();
    private bool isScraperRunning;
    private bool isJsonExtractorRunning;
    private bool isJsonAlreadyParsed;
    private string _selectedCategory = string.Empty;
    private DateTime? _fromDate;
    private DateTime? _toDate;

    private string selectedCategory
    {
        get => _selectedCategory;
        set
        {
            if (_selectedCategory != value)
            {
                _selectedCategory = value;
                UpdateUnscrapedFilteredCount();
            }
        }
    }

    private DateTime? fromDate
    {
        get => _fromDate;
        set
        {
            if (_fromDate != value)
            {
                _fromDate = value;
                UpdateUnscrapedFilteredCount();
            }
        }
    }

    private DateTime? toDate
    {
        get => _toDate;
        set
        {
            if (_toDate != value)
            {
                _toDate = value;
                UpdateUnscrapedFilteredCount();
            }
        }
    }



    protected async override void OnInitialized()
    {
        scrapedArticlesCount = await ArticleService.GetArticlesCountAsync(scraped: true);
        unScrapedArticlesCount = await ArticleService.GetArticlesCountAsync(scraped: false);
        categories = await ArticleService.GetUniqueCategories();
        this._fromDate = DateTime.Now.AddYears(-15);
        this._toDate = DateTime.Now;
        if (this.categories.Any())
        {
            this.selectedCategory = this.categories[0];
            isJsonAlreadyParsed = true;
        }
    }

    public async void OnScrapeClickHandler()
    {
        isScraperRunning = !isScraperRunning;

        if (!isScraperRunning)
            return;

        var unscrapedArticles = await ArticleService.GetArticlesAsync(
                scraped: false,
                category: this.selectedCategory,
                from: this.fromDate.Value,
                to: this.toDate.Value);

        foreach (var article in unscrapedArticles)
        {
            if (!isScraperRunning)
                return;

            string result;
            try
            {
                result = await WebScraper.Scrape(article.WebUrl);
            }
            catch (Exception ex)
            {
                await AddLog($"Problems when scraping article: {ex.Message}");
                article.UrlDoesntExistAnymore = true;
                article.HasBeenScraped = true;
                await ArticleService.UpdateArticleAsync(article);
                continue;
            }
            if (result.Length > 0)
            {
                article.Content = result;
                article.HasBeenScraped = true;
                await ArticleService.UpdateArticleAsync(article);

                articles.Add(article);
                scrapedArticlesCount += 1;
            }

            unScrapedArticlesCount -= 1;
            unScrapedArticlesCountFiltered -= 1;

            var logMessage = article.Content.Length > 0
                ? $"Successfully scraped {article.Content.Length} characters - updated database"
                : "Failure, content is empty";
            await AddLog(logMessage);

            await Task.Delay(4000);
            await AddLog("waiting 4 seconds to reduce load on external website");

        }
        isScraperRunning = false;
        StateHasChanged();
    }
    private async void UpdateUnscrapedFilteredCount()
    {
        if (this.fromDate.HasValue && this.toDate.HasValue && !string.IsNullOrWhiteSpace(this.selectedCategory))
            this.unScrapedArticlesCountFiltered = await ArticleService.GetArticlesCountAsync(
                scraped: false,
                category: this.selectedCategory,
                from: this.fromDate.Value,
                to: this.toDate.Value);

    }

    public async void OnParseJsonClickHandler()
    {
        isJsonExtractorRunning = true;
        await Task.Run(async () => await JsonService.ExtractArticlesFromJsonFile(AddLog));
        isJsonExtractorRunning = false;
        isJsonAlreadyParsed = true;
        OnInitialized();
        StateHasChanged();
    }

    public async Task AddLog(string message)
    {
        var log = $"{DateTime.Now.ToString("G")} - {message}";

        await InvokeAsync(() =>
        {
            this.logs.Insert(0, log);
            while (this.logs.Count > 250)
            {
                this.logs.RemoveAt(this.logs.Count - 1);
            }
            StateHasChanged();
        });
    }

}
